"title","authors","paper","code","huggingface","colab","youtube","topic","poster","compressed_poster","session","is_highlighted"
"DETRs Beat YOLOs on Real-time Object Detection","Yian Zhao, Wenyu Lv, Shangliang Xu, Jinman Wei, Guanzhong Wang, Qingqing Dang, Yi Liu, Jie Chen",https://arxiv.org/abs/2304.08069,https://github.com/lyuwenyu/RT-DETR,,,https://www.youtube.com/watch?v=UOc0qMSX4Ac,"Recognition: Categorization, detection, retrieval",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31301.png?t=1717420504.9897285,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/3732bfdd-4be4-45cd-8353-e056094f9fec,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #229",False
"Alpha-CLIP: A CLIP Model Focusing on Wherever You Want","Zeyi Sun, Ye Fang, Tong Wu, Pan Zhang, Yuhang Zang, Shu Kong, Yuanjun Xiong, Dahua Lin, Jiaqi Wang",https://arxiv.org/abs/2312.03818,https://github.com/SunzeY/AlphaCLIP,https://huggingface.co/spaces/Zery/Alpha-CLIP_LLaVA-1.5,,https://youtu.be/QCEIKPZpZz0,"Vision, language, and reasoning",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31492.png?t=1717327133.6073072,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/4480d88a-7f8f-48c2-bcb0-bde3b694dfd8,"Thu 20 Jun 1:30 p.m. EDT — 3 p.m. EDT #327",False
"YOLO-World: Real-Time Open-Vocabulary Object Detection","Tianheng Cheng, Lin Song, Yixiao Ge, Wenyu Liu, Xinggang Wang, Ying Shan",https://arxiv.org/abs/2401.17270,https://github.com/AILab-CVC/YOLO-World,https://huggingface.co/spaces/SkalskiP/YOLO-World,https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-yolo-world.ipynb,https://youtu.be/X7gKBGVz4vs,"Recognition: Categorization, detection, retrieval",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/f9023a28-aca5-4965-a194-984c62348dc0,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/b9f0bb1e-91d4-4ea3-83c6-ee0817afc1bf,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #223",False
"SpatialTracker: Tracking Any 2D Pixels in 3D Space","Yuxi Xiao, Qianqian Wang, Shangzhan Zhang, Nan Xue, Sida Peng, Yujun Shen, Xiaowei Zhou",https://arxiv.org/abs/2404.04319,https://github.com/henry123-boy/SpaTracker,,,,"3D from multi-view and sensors",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31668.png?t=1717417393.7589533,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/56498f78-2ca0-46ee-9231-6aa1806b6ebc,"Fri 21 Jun 1:30 p.m. EDT — 3 p.m. EDT #84",True
"EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything","Yunyang Xiong, Bala Varadarajan, Lemeng Wu, Xiaoyu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai, Dilin Wang, Fei Sun, Forrest Iandola, Raghuraman Krishnamoorthi, Vikas Chandra",https://arxiv.org/abs/2312.00863,https://github.com/yformer/EfficientSAM,https://huggingface.co/spaces/SkalskiP/EfficientSAM,,,"Efficient and scalable vision",,,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #144",True
"DemoFusion: Democratising High-Resolution Image Generation With No $$$","Ruoyi Du, Dongliang Chang, Timothy Hospedales, Yi-Zhe Song, Zhanyu Ma",https://arxiv.org/abs/2311.16973,https://github.com/PRIS-CV/DemoFusion,https://huggingface.co/spaces/radames/Enhance-This-DemoFusion-SDXL,https://colab.research.google.com/github/camenduru/DemoFusion-colab/blob/main/DemoFusion_colab.ipynb,,"Image and video synthesis and generation",,,"Wed 19 Jun 8 p.m. EDT — 9:30 p.m. EDT #132",False
"Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs","Shengbang Tong, Zhuang Liu, Yuexiang Zhai, Yi Ma, Yann LeCun, Saining Xie",https://arxiv.org/abs/2401.06209,https://github.com/tsb0601/MMVP,,,,"Vision, language, and reasoning",,,"Thu 20 Jun 1:30 p.m. EDT — 3 p.m. EDT #390",True
"ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models","Lukas Höllein, Aljaž Božič, Norman Müller, David Novotny, Hung-Yu Tseng, Christian Richardt, Michael Zollhöfer, Matthias Nießner",https://arxiv.org/abs/2403.01807,https://github.com/facebookresearch/ViewDiff,,,https://youtu.be/SdjoCqHzMMk,"3D from multi-view and sensors",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31616.png?t=1716470830.0209699,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/0453bf88-9d54-4ecf-8a45-01af0f604faf,"Wed 19 Jun 8 p.m. EDT — 9:30 p.m. EDT #20",False
"LISA: Reasoning Segmentation via Large Language Model","Xin Lai, Zhuotao Tian, Yukang Chen, Yanwei Li, Yuhui Yuan, Shu Liu, Jiaya Jia",https://arxiv.org/abs/2308.00692,https://github.com/dvlab-research/LISA,http://103.170.5.190:7870/,,,"Vision, language, and reasoning",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30109.png?t=1717509456.89997,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/fc2699d9-7bd2-4c3a-8e6c-4961505cc802,"Thu 20 Jun 1:30 p.m. EDT — 3 p.m. EDT #413",True
"Matching Anything by Segmenting Anything","Siyuan Li, Lei Ke, Martin Danelljan, Luigi Piccinelli, Mattia Segu, Luc Van Gool, Fisher Yu",https://arxiv.org/abs/2406.04221,https://github.com/siyuanliii/masa,,,https://youtu.be/KDQVujKAWFQ,"Video: Low-level analysis, motion, and tracking",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/29590.png?t=1717456006.3308516,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/bb451f47-ba3e-4e34-a7c0-3410b64d9339,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #421",True
"DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction","Weiyi Lv, Yuhang Huang, Ning Zhang, Ruei-Sung Lin, Mei Han, Dan Zeng",https://arxiv.org/abs/2403.02075,https://github.com/Kroery/DiffMOT,,,,"Video: Low-level analysis, motion, and tracking",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/9711186c-b05b-472d-b095-d98dbe386171,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/18caf2db-5dab-4251-9eeb-e2397c67eb3f,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #455",False
"RobustSAM: Segment Anything Robustly on Degraded Images","Wei-Ting Chen, Yu-Jiet Vong, Sy-Yen Kuo, Sizhou Ma, Jian Wang",https://openaccess.thecvf.com/content/CVPR2024/html/Chen_RobustSAM_Segment_Anything_Robustly_on_Degraded_Images_CVPR_2024_paper.html,,,,https://www.youtube.com/watch?v=Awukqkbs6zM,"Segmentation, grouping and shape analysis",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/62d34981-73d6-49b2-8058-46ec99bac94d,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/ee15d3bc-c391-44f9-b35b-24af714ef119,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #378",True
"Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation","Bingfeng Zhang, Siyue Yu, Yunchao Wei, Yao Zhao, Jimin Xiao",https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Frozen_CLIP_A_Strong_Backbone_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.html,https://github.com/zbf1991/WeCLIP,,,https://youtu.be/Lh489nTm_M0,"Segmentation, grouping and shape analysis",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30253.png?t=1716781257.513028,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/0c43b789-f2e8-4ff9-ae46-b5a87de1b921,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #351",True
"ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual Prompts","Mu Cai, Haotian Liu, Dennis Park, Siva Karthik Mustikovela, Gregory P. Meyer, Yuning Chai, Yong Jae Lee",https://arxiv.org/abs/2312.00784,https://github.com/WisconsinAIVision/ViP-LLaVA,https://pages.cs.wisc.edu/~mucai/vip-llava.html,,https://youtu.be/j_l1bRQouzc,"Vision, language, and reasoning",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/53e03a08-4dd9-451a-975e-e3654fa5bc71,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/6d1536ae-3f96-49d9-a05f-9648b925cdb5,"Thu 20 Jun 1:30 p.m. EDT — 3 p.m. EDT #317",False
"DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing","Yujun Shi, Chuhui Xue, Jun Hao Liew, Jiachun Pan, Hanshu Yan, Wenqing Zhang, Vincent Y. F. Tan, Song Bai",https://arxiv.org/abs/2306.14435,https://github.com/Yujun-Shi/DragDiffusion,,,https://youtu.be/rysOFTpDBhc,"Image and video synthesis and generation",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/b0833f6b-6924-4f28-b409-ae85aaaa4dd6,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/2a0219f5-9f1e-47e1-a968-d4d98154feb2,"Wed 19 Jun 8 p.m. EDT — 9:30 p.m. EDT #392",True
"OmniGlue: Generalizable Feature Matching with Foundation Model Guidance","Hanwen Jiang, Arjun Karpur, Bingyi Cao, Qixing Huang, Andre Araujo",https://arxiv.org/abs/2405.12979,https://github.com/google-research/omniglue,https://huggingface.co/spaces/qubvel-hf/omniglue,,,"3D from multi-view and sensors",,,"Fri 21 Jun 1:30 p.m. EDT — 3 p.m. EDT #32",False
"DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks","Jiaxin Zhang, Dezhi Peng, Chongyu Liu, Peirong Zhang, Lianwen Jin",https://arxiv.org/abs/2405.04408,https://github.com/ZZZHANG-jx/DocRes,https://huggingface.co/spaces/qubvel-hf/documents-restoration,,,"Document analysis and understanding",,,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #101",False
"XFeat: Accelerated Features for Lightweight Image Matching","Guilherme Potje, Felipe Cadar, Andre Araujo, Renato Martins, Erickson R. Nascimento",https://arxiv.org/abs/2404.19174,https://github.com/verlab/accelerated_features,https://huggingface.co/spaces/qubvel-hf/xfeat,https://colab.research.google.com/github/verlab/accelerated_features/blob/main/notebooks/xfeat_matching.ipynb,https://youtu.be/RamC70IkZuI,"Low-level vision",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/8eb6b4f0-4ae6-4615-9921-f73fa2aa3766,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/50b6d16f-c2d8-49a4-8c15-a31d6f9a3c44,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #245",False
"Improved Baselines with Visual Instruction Tuning","Haotian Liu, Chunyuan Li, Yuheng Li, Yong Jae Lee",https://arxiv.org/abs/2310.03744,https://github.com/LLaVA-VL/LLaVA-NeXT,,,,"Multi-modal learning",,,"Fri 21 Jun 8 p.m. EDT — 9:30 p.m. EDT #209",True
"Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks","Bin Xiao, Haiping Wu, Weijian Xu, Xiyang Dai, Houdong Hu, Yumao Lu, Michael Zeng, Ce Liu, Lu Yuan",https://arxiv.org/pdf/2311.06242,,https://huggingface.co/spaces/gokaygokay/Florence-2,https://youtu.be/cOlyA00K1ec,https://youtu.be/cOlyA00K1ec,"Deep learning architectures and techniques",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30529.png?t=1717455193.7819567,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/4aaf3f87-cc62-4fa3-af99-c8c1c83c0069,"Wed 19 Jun 8 p.m. EDT — 9:30 p.m. EDT #102",True
"Semantic-aware SAM for Point-Prompted Instance Segmentation","Zhaoyang Wei, Pengfei Chen, Xuehui Yu, Guorong Li, Jianbin Jiao, Zhenjun Han",https://arxiv.org/abs/2312.15895,https://github.com/zhaoyangwei123/SAPNet,,,https://youtu.be/42-tJFmT7Ao,"Segmentation, grouping and shape analysis",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/2f2bf794-3981-48c8-992d-04dd32ee9ced,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/f1ed2755-1df1-45fe-810b-5fc98b4b52e1,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #331",True
"In-Context Matting","He Guo, Zixuan Ye, Zhiguo Cao, Hao Lu",https://arxiv.org/abs/2403.15789,https://github.com/tiny-smart/in-context-matting,,,,"Segmentation, grouping and shape analysis",,,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #343",True
"Robust Image Denoising through Adversarial Frequency Mixup","Donghun Ryou, Inju Ha, Hyewon Yoo, Dongwan Kim, Bohyung Han",https://openaccess.thecvf.com/content/CVPR2024/html/Ryou_Robust_Image_Denoising_through_Adversarial_Frequency_Mixup_CVPR_2024_paper.html,https://github.com/dhryougit/AFM,,,https://youtu.be/zQ0pwFSk7uo,"Low-level vision",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/038bef8f-a6df-440d-9ebc-b58f69beb338,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/03cc753c-f875-479e-bca2-e0375e9929a6,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #250",False
"General Object Foundation Model for Images and Videos at Scale","Junfeng Wu, Yi Jiang, Qihao Liu, Zehuan Yuan, Xiang Bai, Song Bai",https://arxiv.org/abs/2312.09158,https://github.com/FoundationVision/GLEE,,,https://www.youtube.com/watch?v=PSVhfTPx0GQ,"Segmentation, grouping and shape analysis",https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/bfe79038-706d-491b-ac99-083f421dc5ec,https://github.com/SkalskiP/top-cvpr-2024-papers/assets/26109316/4f0ed38d-28aa-4766-b290-940cbc6711d6,"Wed 19 Jun 1:30 p.m. EDT — 3 p.m. EDT #350",True
"MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training","Pavan Kumar Anasosalu Vasu, Hadi Pouransari, Fartash Faghri, Raviteja Vemulapalli, Oncel Tuzel",https://arxiv.org/abs/2311.17049,https://github.com/apple/ml-mobileclip,https://huggingface.co/spaces/Xenova/webgpu-mobileclip,,,"Efficient and scalable vision",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30022.png?t=1718402790.003817,,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #130",False
"Object Recognition as Next Token Prediction","Kaiyu Yue, Bor-Chun Chen, Jonas Geiping, Hengduo Li, Tom Goldstein, Ser-Nam Lim",https://arxiv.org/abs/2312.02142,https://github.com/kaiyuyue/nxtp,,https://colab.research.google.com/drive/1pJX37LP5xGLDzD3H7ztTmpq1RrIBeWX3?usp=sharing,https://youtu.be/xeI8dZIpoco,"Recognition: Categorization, detection, retrieval",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31732.png?t=1717298372.5822952,,"Thu 20 Jun 8 p.m. EDT — 9:30 p.m. EDT #199",True
"MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI","Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen",https://arxiv.org/abs/2311.16502,,,,,"Vision, language, and reasoning",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31040.png?t=1718300473.5736258,,"Thu 20 Jun 1:30 p.m. EDT — 3 p.m. EDT #382",True
"InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks","Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Bin Li, Ping Luo, Tong Lu, Yu Qiao, Jifeng Dai",https://arxiv.org/abs/2312.14238,https://github.com/OpenGVLab/InternVL,https://huggingface.co/spaces/OpenGVLab/InternVL,,,"Self-supervised or unsupervised representation learning",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30014.png?t=1717339970.9614518,,"Fri 21 Jun 8 p.m. EDT — 9:30 p.m. EDT #412",True
"Describing Differences in Image Sets with Natural Language","Lisa Dunlap, Yuhui Zhang, Xiaohan Wang, Ruiqi Zhong, Trevor Darrell, Jacob Steinhardt, Joseph E. Gonzalez, Serena Yeung-Levy",https://arxiv.org/abs/2312.02974,https://github.com/Understanding-Visual-Datasets/VisDiff,,,,"Explainable computer vision",,,"Fri 21 Jun 8 p.m. EDT — 9:30 p.m. EDT #115",True
"Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models","Daniel Geng, Inbum Park, Andrew Owens",https://arxiv.org/abs/2311.17919,https://github.com/dangeng/visual_anagrams,,https://colab.research.google.com/github/dangeng/visual_anagrams/blob/main/notebooks/colab_demo_free_tier.ipynb,,"Image and video synthesis and generation",https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30657.png?t=1717473392.6694562,,"Fri 21 Jun 8 p.m. EDT — 9:30 p.m. EDT #118",True